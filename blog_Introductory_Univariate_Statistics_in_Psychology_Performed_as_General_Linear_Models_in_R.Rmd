---
title: "Introductory Univariate Statistics in Psychology Performed as General Linear Models (GLM) in R"
subtitle: "A comparison of typical introductory univariate statistics in psychology performed as regressions (or GLMs) in R"
date: "Date Posted"
output:
  html_document:
    highlight: textmate
    theme: lumen
    toc: yes
    toc_depth: 3
    code_folding: show
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(psych); library(knitr)
```

*Tags:* <span class="badge badge-pill badge-light">Statistics</span>
<span class="badge badge-pill badge-primary">R</span>

<BR><BR>

Typically, introductory univariate statistics psychology courses cover the following inferential analyses (plus or minus a few more):

* one sample *t*-test
* dependent samples *t*-test
* independent samples *t*-test,
* one-way Analysis of Variance (ANOVA),
* factorial ANOVA, and
* correlation

Although, these conventions may be useful for quickly talking about these particular statistical analyses with others, I generally find it helpful to think about these analyses within the framework of the general linear model (GLM). I believe that thinking of these analyses as derivates of the GLM lends itself to understanding more advanced techniques. Given that, I want to provide some evidence (and R code) for others to see how the aforementioned analyses can be analyzed within the GLM framework with identical answers.

In the following examples, the conventional name and its respective analysis is conducted on the left, while the same analysis performed in the GLM framework is performed on the right.

Note: There are other ways to analyze GLM in R than the codes I have provided.

<BR><BR>

## One Sample *t*-Test

First, let's go over the one-sample *t*-test, which compares a sample mean to a population mean. 

For example, lets say that I was interested in seeing if people that visit my blog have a different level of resourcefulness than the general population. Resourcefulness was fictitously measured on a Likert-scale from -3 to +3 with -3 representing extremely not resourceful, 0 representing a moderate level of resourcefulness and +3 representing extremely resourceful. 

Let's also say that the population on average has a moderate level of resourcefulness, $\mu = 0$, and I collected the resourcefulness level from a sample of 100 individuals that have visited my blog.

```{r dataset_one_sample_ttest}

# sample 10 random numbers drawn from -3 and 3 with replacement
sample <- sample(-3:3, 100, replace=T)

# define sample as dataframe and call it dataset
dataset <- data.frame(sample)

# view the dataset
head(dataset)

# descriptive statistics using the psych package
describe(dataset)

```

<BR>

Before running the analyses in R, let's compare the differences in the null and research hypotheses using each technique.

<BR>

<div class="divTable">
<div class="divTableBody">

<div class="divTableRow">
<div class="divTableCell" style="width: 50%; text-align: center">

<CENTER>**One-Sample *t*-Test**</CENTER>

$H_0: \mu_{Sample} = 0$
<BR>$H_1: \mu_{Sample} \ne 0$

</div>
<div class="divTableCell" style="width: 50%; text-align: center; vertical-align: middle">

<CENTER>**GLM**</CENTER>

$Model: Resourcefulness = \beta_0 + \varepsilon$

$H_0: \beta_0 = 0$
<BR>$H_1: \beta_0 \ne 0$

</div>
</div>

</div>
</div>

<BR>

In the GLM framework, without additional information (i.e., predictors), the single best predictor of resourcefulness is the sample mean. Thus, the intercept represents the sample mean and is testing if the sample mean of resourcefulness is significantly different than 0.

<BR>
<div class="divTable">
<div class="divTableBody">

<div class="divTableRow">
<div class="divTableCell" style="width: 50%">

<CENTER>**One-Sample *t*-Test**</CENTER>

```{r}

# one sample t-test
t.test(x = sample)

```

</div>
<div class="divTableCell" style="width: 50%">

<CENTER>**GLM**</CENTER>

```{r}

# write the GLM and save it as model
# within the lm function, 1 indicates a test of the intercept against zero
# which is identical to a one sample t-test against zero.
model <- lm(sample ~ 1)

# summarize the model
summary(model)

# confidence interval of the model
confint(model)

```

</div>
</div>

</div>
</div>

<BR>

```{r, include=FALSE}

model <- lm(sample ~ 1)
summary <- summary(model)
confint <- confint(model)

```

Notice that in both analyses the values are identical with respect to place of rounding. The sample mean is `r round(summary$coefficients[1],2)`, the *t*-statistic is `r round(summary$coefficients[3],2)` with `r round(summary$df[2],0)` degrees of freedom (df), and the *p*-value is `r round(summary$coefficients[4],2)`.

<BR><BR><BR>

## Dependent Samples *t*-Test

Next, let's go over the dependent samples t-test, which is essentially the same analysis as the one sample *t*-test but on a difference score.

For this analysis, let's say that I was interested in seeing if people who read my blog had a different level of self-efficacy after visiting my blog than before visiting my blog. Self-efficacy was fictiously measured on a Likert-scale from -3 to +3 where -3 represents extremely low levels of self-efficacy, 0 represents moderate levels of self-efficacy, and +3 represents extremely high levels of self-efficacy. Let's say that I was able to collect levels of self-confidence before and after visiting my blog from 100 individuals.


```{r dataset_dependent_samples_ttest}

# randomly sample 100 numbers from -3 to 3 with replacement
before <- sample(-3:3,100,replace = T)

# randomly sample 100 numbers from -3 to 3 with replacement
after <- sample(-3:3,100,replace = T)

# subtract after from before to obtain a difference score
difference <- after-before

# save the variables into a dataframe known as dataset 
dataset <- data.frame(before,after,difference)

# view the dataset
head(dataset)

# descriptive statistics
describe(dataset)

```

<BR>

Before running the analyses in R, letâ€™s compare the differences in the null and research hypotheses using each technique.

<BR>

<div class="divTable">
<div class="divTableBody">

<div class="divTableRow">
<div class="divTableCell" style="width: 50%; text-align: center">

<CENTER>**Dependent Samples *t*-Test**</CENTER>

$H_0: \mu_{After}-\mu_{Before} = 0$ or equivalently $H_0: \mu_{Difference} = 0$
<BR>$H_1: \mu_{After}-\mu_{Before} \ne 0$ or equivalently $H_1: \mu_{Difference} \ne 0$

</div>
<div class="divTableCell" style="width: 50%; text-align: center">

<CENTER>**GLM**</CENTER>

$Model: Difference = \beta_0 + \varepsilon$

$H_0: \beta_0 = 0$
<BR>$H_1: \beta_0 \ne 0$

</div>
</div>

</div>
</div>

<BR>

Just like in the one sample *t*-test, the intercept represents the sample mean. However, in this case the sample mean is the sample mean of the difference since the dependent variable is the difference score of self-confidence levels. Thus, the intercept here is testing if the sample mean of the difference in self-confidence levels is significantly different than 0.

<BR>

<div class="divTable">
<div class="divTableBody">

<div class="divTableRow">
<div class="divTableCell" style="width: 50%">

<CENTER>**Dependent Samples *t*-test**</CENTER>

```{r}

# dependent samples t-test
t.test(after,before,paired = TRUE)

```

</div>
<div class="divTableCell" style="width: 50%">

<CENTER>**GLM**</CENTER>

```{r}

# define the GLM and save it as model
model <- lm(difference ~ 1)

# summarize the model
summary(model)

# confidence interval of the model parameter estimates
confint(model)

```

</div>
</div>

</div>
</div>


```{r, include=FALSE}

model <- lm(difference ~ 1)
summary <- summary(model)
confint <- confint(model)

```

Again, note that in both analyses the sample mean difference of `r round(summary$coefficients[1],2)`, the *t*-statistic of `r round(summary$coefficients[3],2)` with `r round(summary$df[2],0)` degrees of freedom (df), and the *p*-value of `r round(summary$coefficients[4],2)` are identical with respective to place of rounding.


<BR><BR><BR>

## Independent Samples *t*-Test

For this analysis, let's say that I was interested in understanding if level of self-confidence is different after viewing my blog than after visiting a news website. Self-condfidence was measured using the same measure from the prior analysis.

Let's say that I randomly assigned 100 participants to either visit my blog or visit a news website, and measured their level of self-confidence afterwards. Those were visited my blog were coded as 0.5 while those who visited a news website were coded as -0.5 under the variable condition.

```{r dataset_independent_samples_ttest}

self_confidence <- sample(-3:3,100,replace = T)

# set x to  random groups
condition <- sample(-0.5:0.5,100,replace=T)

# save the variables into a dataframe as dataset
dataset <- data.frame(self_confidence, condition)

# view the dataset
head(dataset)

# describe the the variable Y for each of the groups
describeBy(dataset$self_confidence, group=dataset$condition)

```

<BR>

Again, let's compare the null and research hypotheses before we perform the analyses.

<BR>

<div class="divTable">
<div class="divTableBody">

<div class="divTableRow">
<div class="divTableCell" style="width: 50%; text-align: center">

<CENTER>**Independent Samples *t*-test**</CENTER>

$H_0: \mu_{Blog} - \mu_{News} = 0$ or equivalently $\mu_{Blog} = \mu_{News}$
<BR>$H_1: \mu_{Blog} - \mu_{News} \ne 0$ or equivalently $\mu_{Blog} = \mu_{News}$

</div>
<div class="divTableCell" style="width: 50%; text-align: center">

<CENTER>**GLM**</CENTER>

$Model: Self\_Confidence = \beta_0 + \beta_1*Condition + \varepsilon$
$H_0: \beta_1 = 0$
<BR>$H_1: \beta_1 \ne 0$

</div>
</div>

</div>
</div>
<div class="divTable">
<div class="divTableBody">

<div class="divTableRow">
<div class="divTableCell" style="width: 50%">

<CENTER>**Independent Samples *t*-test**</CENTER>

```{r}

# independent samples t-test
t.test(self_confidence ~ condition, var.equal=TRUE)

```

</div>
<div class="divTableCell" style="width: 50%">

<CENTER>**GLM**</CENTER>

```{r}

# GLM
model <- lm(self_confidence ~ condition)

# summary of the GLM
summary(model)

# confidence interval of the GLM parameter esimates 
confint(model)

```

</div>
</div>

</div>
</div>

```{r, include = FALSE}

# GLM
model <- lm(self_confidence ~ condition)

# summary of the GLM
summary <- summary(model)

# confidence interval of the GLM parameter esimates 
confint <- confint(model)
```

Note that in both analyses the *t*-statistic of `r round(summary$coefficients[2,3],2)` with `r round(summary$df[2],0)` degrees of freedom (df), and *p*-value of `r round(summary$coefficients[2,4],2)` are identical.

<BR><BR><BR>

## One-Way ANOVA

```{r dataset_one_way_anova}

y <- rnorm(1:15)
x <- c("group1","group1","group1","group1","group1","group2","group2","group2","group2","group2","group3","group3","group3","group3","group3")
dataset <- data.frame(y, x)
dataset
describeBy(dataset$y, group = x)

```

<div class="divTable">
<div class="divTableBody">

<div class="divTableRow">
<div class="divTableCell" style="width: 50%">

<CENTER>**Typical**</CENTER>

```{r}

model <- aov(y ~ x)
anova(model)

```

</div>
<div class="divTableCell" style="width: 50%">

<CENTER>**GLM**</CENTER>

```{r}

model <- lm(y ~ x)
anova(model)
summary(model)
confint(model)

```

</div>
</div>

</div>
</div>

<BR><BR><BR>

## Factorial ANOVA

```{r dataset_factorial_anova}

y <- rnorm(1:15)
x1 <- c("group1","group1","group1","group1","group1","group2","group2","group2","group2","group2","group3","group3","group3","group3","group3")
x2 <- c("group1","group2","group3","group1","group2","group3","group1","group2","group3","group1","group2","group3","group1","group2","group3")
dataset <- data.frame(y, x1, x2)
dataset
describeBy(dataset$y, group = list(dataset$x1, dataset$x2))

```

<div class="divTable">
<div class="divTableBody">

<div class="divTableRow">
<div class="divTableCell" style="width: 50%">

<CENTER>**Typical**</CENTER>

```{r}

model <- aov(y ~ x1*x2)
anova(model)

```

</div>
<div class="divTableCell" style="width: 50%">

<CENTER>**GLM**</CENTER>

```{r}

model <- lm(y ~ x1*x2)
anova(model)
summary(model)
confint(model)

```

</div>
</div>

</div>
</div>

<BR><BR><BR>

## Correlation

```{r dataset_correlation}

y <- rnorm(1:10)
x <- rnorm(1:10)
dataset <- data.frame(y,x)
dataset
describe(dataset)

```

<div class="divTable">
<div class="divTableBody">

<div class="divTableRow">
<div class="divTableCell" style="width: 50%">

<CENTER>**Typical**</CENTER>

```{r}

cor.test(x, y)

```

</div>
<div class="divTableCell" style="width: 50%">

<CENTER>**GLM**</CENTER>

```{r}

model <- lm(scale(y) ~ scale(x))
anova(model)
summary(model)
confint(model)

```

</div>
</div>

</div>
</div>

Some may have learned these analyses under different names. For example, some may have learned the dependent samples *t*-test was called paired or matched samples *t*-test. Regardless of the specific nomenclature, these are generally the analyses I have seen covered from being a graduate teaching assistant for statistics courses in psychology as well as from being a tutor of statistics courses. 

Note that the test statistic and its respective *p*-value are identical using either method (i.e., the typical univariate introductory statistics for psychology vs. GLM). Also, note that the GLM provides the same information as the ANOVA with the addition of 1 degree of freedom (*df*) tests. Thus, to take advantage of the 1 *df* test with categorical predictors (e.g., in the ANOVA), meaningful *a priori* contrasts are preferred over pre-programmed contrasts, especially in research.

In either case, APA format of these results would be something like the following:
*M* = `r round(summary$coefficients[1],2)`, 95% CI [`r round(confint[1],2)`, `r round(confint[2],2)`] *t*(`r round(summary$df[2],0)`) = `r round(summary$coefficients[3],2)`, *p* = `r round(summary$coefficients[4],2)`
