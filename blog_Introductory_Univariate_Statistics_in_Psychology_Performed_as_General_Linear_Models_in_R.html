<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Introductory Univariate Statistics in Psychology Performed as General Linear Models (GLM) in R</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/lumen.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116039246-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-116039246-1');
</script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 54px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 59px;
  margin-top: -59px;
}

.section h2 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h3 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h4 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h5 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h6 {
  padding-top: 59px;
  margin-top: -59px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">



<nav class="navbar navbar-default navbar-expand-lg navbar-dark bg-primary navbar-fixed-top">

  <div class="container">
      <a class="navbar-brand" href="index.html">Ekarin Eric Pongpipat, M.A.</a>
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbarColor01" aria-controls="navbarColor01" aria-expanded="false" aria-label="Toggle navigation" style="">
        <span class="navbar-toggler-icon"></span>
      </button>

    <div id="navbarColor01" class="collapse navbar-collapse">
      <ul class="nav navbar-nav navbar-right mr-auto">
        <li class="nav-item">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="about.html">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="CV.html">CV</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="blog.html">Blog</a>
        </li>
      </ul>
    </div><!--/.nav-collapse -->

  </div><!--/.container -->

</nav><!--/.navbar -->
<nav class="navbar navbar-default navbar-expand-lg navbar-dark bg-primary navbar-fixed-top">

  <div class="container">
      <a class="navbar-brand" href="index.html">Ekarin Eric Pongpipat, M.A.</a>
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbarColor01" aria-controls="navbarColor01" aria-expanded="false" aria-label="Toggle navigation" style="">
        <span class="navbar-toggler-icon"></span>
      </button>

    <div id="navbarColor01" class="collapse navbar-collapse">
      <ul class="nav navbar-nav navbar-right mr-auto">
        <li class="nav-item">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="about.html">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="CV.html">CV</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="blog.html">Blog</a>
        </li>
      </ul>
    </div><!--/.nav-collapse -->

  </div><!--/.container -->

</nav><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Introductory Univariate Statistics in Psychology Performed as General Linear Models (GLM) in R</h1>
<h3 class="subtitle"><em>A comparison of typical introductory univariate statistics in psychology performed as regressions (or GLMs) in R</em></h3>
<h4 class="date"><em>Date Posted</em></h4>

</div>


<p><em>Tags:</em> <span class="badge badge-pill badge-light">Statistics</span> <span class="badge badge-pill badge-primary">R</span></p>
<p><BR><BR></p>
<p>Typically, introductory univariate statistics psychology courses cover the following inferential analyses (plus or minus a few more):</p>
<ul>
<li>one sample <em>t</em>-test</li>
<li>dependent samples <em>t</em>-test</li>
<li>independent samples <em>t</em>-test,</li>
<li>one-way Analysis of Variance (ANOVA),</li>
<li>factorial ANOVA, and</li>
<li>correlation</li>
</ul>
<p>Although, these conventions may be useful for quickly talking about these particular statistical analyses with others, I generally find it helpful to think about these analyses within the framework of the general linear model (GLM). I believe that thinking of these analyses as derivates of the GLM lends itself to understanding more advanced techniques. Given that, I want to provide some evidence (and R code) for others to see how the aforementioned analyses can be analyzed within the GLM framework with identical answers.</p>
<p>In the following examples, the conventional name and its respective analysis is conducted on the left, while the same analysis performed in the GLM framework is performed on the right.</p>
<p>Note: There are other ways to analyze GLM in R than the codes I have provided.</p>
<p><BR><BR></p>
<div id="one-sample-t-test" class="section level2">
<h2>One Sample <em>t</em>-Test</h2>
<p>First, let’s go over the one-sample <em>t</em>-test, which compares a sample mean to a population mean.</p>
<p>For example, lets say that I was interested in seeing if people that visit my blog have a different level of resourcefulness than the general population. Resourcefulness was fictitously measured on a Likert-scale from -3 to +3 with -3 representing extremely not resourceful, 0 representing a moderate level of resourcefulness and +3 representing extremely resourceful.</p>
<p>Let’s also say that the population on average has a moderate level of resourcefulness, <span class="math inline">\(\mu = 0\)</span>, and I collected the resourcefulness level from a sample of 100 individuals that have visited my blog.</p>
<pre class="r"><code># sample 10 random numbers drawn from -3 and 3 with replacement
sample &lt;- sample(-3:3, 100, replace=T)

# define sample as dataframe and call it dataset
dataset &lt;- data.frame(sample)

# view the dataset
head(dataset)</code></pre>
<pre><code>##   sample
## 1     -1
## 2      1
## 3      1
## 4      3
## 5      0
## 6      1</code></pre>
<pre class="r"><code># descriptive statistics using the psych package
describe(dataset)</code></pre>
<pre><code>##        vars   n mean   sd median trimmed  mad min max range  skew kurtosis
## sample    1 100 0.21 2.01      0    0.26 2.97  -3   3     6 -0.09    -1.21
##         se
## sample 0.2</code></pre>
<p><BR></p>
<p>Before running the analyses in R, let’s compare the differences in the null and research hypotheses using each technique.</p>
<p><BR></p>
<div class="divTable">
<div class="divTableBody">
<div class="divTableRow">
<div class="divTableCell" style="width: 50%; text-align: center">
<CENTER>
<strong>One-Sample <em>t</em>-Test</strong>
</CENTER>
<p><span class="math inline">\(H_0: \mu_{Sample} = 0\)</span> <BR><span class="math inline">\(H_1: \mu_{Sample} \ne 0\)</span></p>
</div>
<div class="divTableCell" style="width: 50%; text-align: center; vertical-align: middle">
<CENTER>
<strong>GLM</strong>
</CENTER>
<p><span class="math inline">\(Model: Resourcefulness = \beta_0 + \varepsilon\)</span></p>
<p><span class="math inline">\(H_0: \beta_0 = 0\)</span> <BR><span class="math inline">\(H_1: \beta_0 \ne 0\)</span></p>
</div>
</div>
</div>
</div>
<p><BR></p>
<p>In the GLM framework, without additional information (i.e., predictors), the single best predictor of resourcefulness is the sample mean. Thus, the intercept represents the sample mean and is testing if the sample mean of resourcefulness is significantly different than 0.</p>
<BR>
<div class="divTable">
<div class="divTableBody">
<div class="divTableRow">
<div class="divTableCell" style="width: 50%">
<CENTER>
<strong>One-Sample <em>t</em>-Test</strong>
</CENTER>
<pre class="r"><code># one sample t-test
t.test(x = sample)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  sample
## t = 1.044, df = 99, p-value = 0.299
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -0.1891367  0.6091367
## sample estimates:
## mean of x 
##      0.21</code></pre>
</div>
<div class="divTableCell" style="width: 50%">
<CENTER>
<strong>GLM</strong>
</CENTER>
<pre class="r"><code># write the GLM and save it as model
# within the lm function, 1 indicates a test of the intercept against zero
# which is identical to a one sample t-test against zero.
model &lt;- lm(sample ~ 1)

# summarize the model
summary(model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = sample ~ 1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##  -3.21  -1.21  -0.21   1.79   2.79 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.2100     0.2012   1.044    0.299
## 
## Residual standard error: 2.012 on 99 degrees of freedom</code></pre>
<pre class="r"><code># confidence interval of the model
confint(model)</code></pre>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) -0.1891367 0.6091367</code></pre>
</div>
</div>
</div>
</div>
<p><BR></p>
<p>Notice that in both analyses the values are identical with respect to place of rounding. The sample mean is 0.21, the <em>t</em>-statistic is 1.04 with 99 degrees of freedom (df), and the <em>p</em>-value is 0.3.</p>
<p><BR><BR><BR></p>
</div>
<div id="dependent-samples-t-test" class="section level2">
<h2>Dependent Samples <em>t</em>-Test</h2>
<p>Next, let’s go over the dependent samples t-test, which is essentially the same analysis as the one sample <em>t</em>-test but on a difference score.</p>
<p>For this analysis, let’s say that I was interested in seeing if people who read my blog had a different level of self-efficacy after visiting my blog than before visiting my blog. Self-efficacy was fictiously measured on a Likert-scale from -3 to +3 where -3 represents extremely low levels of self-efficacy, 0 represents moderate levels of self-efficacy, and +3 represents extremely high levels of self-efficacy. Let’s say that I was able to collect levels of self-confidence before and after visiting my blog from 100 individuals.</p>
<pre class="r"><code># randomly sample 100 numbers from -3 to 3 with replacement
before &lt;- sample(-3:3,100,replace = T)

# randomly sample 100 numbers from -3 to 3 with replacement
after &lt;- sample(-3:3,100,replace = T)

# subtract after from before to obtain a difference score
difference &lt;- after-before

# save the variables into a dataframe known as dataset 
dataset &lt;- data.frame(before,after,difference)

# view the dataset
head(dataset)</code></pre>
<pre><code>##   before after difference
## 1     -1     0          1
## 2     -3     0          3
## 3     -3    -1          2
## 4      2     3          1
## 5     -1    -1          0
## 6      1     0         -1</code></pre>
<pre class="r"><code># descriptive statistics
describe(dataset)</code></pre>
<pre><code>##            vars   n  mean   sd median trimmed  mad min max range  skew
## before        1 100  0.04 1.94      0    0.05 2.97  -3   3     6 -0.03
## after         2 100 -0.13 1.97      0   -0.16 2.97  -3   3     6  0.06
## difference    3 100 -0.17 2.85      0   -0.20 2.97  -6   6    12  0.13
##            kurtosis   se
## before        -1.20 0.19
## after         -1.21 0.20
## difference    -0.52 0.28</code></pre>
<p><BR></p>
<p>Before running the analyses in R, let’s compare the differences in the null and research hypotheses using each technique.</p>
<p><BR></p>
<div class="divTable">
<div class="divTableBody">
<div class="divTableRow">
<div class="divTableCell" style="width: 50%; text-align: center">
<CENTER>
<strong>Dependent Samples <em>t</em>-Test</strong>
</CENTER>
<p><span class="math inline">\(H_0: \mu_{After}-\mu_{Before} = 0\)</span> or equivalently <span class="math inline">\(H_0: \mu_{Difference} = 0\)</span> <BR><span class="math inline">\(H_1: \mu_{After}-\mu_{Before} \ne 0\)</span> or equivalently <span class="math inline">\(H_1: \mu_{Difference} \ne 0\)</span></p>
</div>
<div class="divTableCell" style="width: 50%; text-align: center">
<CENTER>
<strong>GLM</strong>
</CENTER>
<p><span class="math inline">\(Model: Difference = \beta_0 + \varepsilon\)</span></p>
<p><span class="math inline">\(H_0: \beta_0 = 0\)</span> <BR><span class="math inline">\(H_1: \beta_0 \ne 0\)</span></p>
</div>
</div>
</div>
</div>
<p><BR></p>
<p>Just like in the one sample <em>t</em>-test, the intercept represents the sample mean. However, in this case the sample mean is the sample mean of the difference since the dependent variable is the difference score of self-confidence levels. Thus, the intercept here is testing if the sample mean of the difference in self-confidence levels is significantly different than 0.</p>
<p><BR></p>
<div class="divTable">
<div class="divTableBody">
<div class="divTableRow">
<div class="divTableCell" style="width: 50%">
<CENTER>
<strong>Dependent Samples <em>t</em>-test</strong>
</CENTER>
<pre class="r"><code># dependent samples t-test
t.test(after,before,paired = TRUE)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  after and before
## t = -0.5965, df = 99, p-value = 0.5522
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.7354957  0.3954957
## sample estimates:
## mean of the differences 
##                   -0.17</code></pre>
</div>
<div class="divTableCell" style="width: 50%">
<CENTER>
<strong>GLM</strong>
</CENTER>
<pre class="r"><code># define the GLM and save it as model
model &lt;- lm(difference ~ 1)

# summarize the model
summary(model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = difference ~ 1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##  -5.83  -1.83   0.17   2.17   6.17 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   -0.170      0.285  -0.596    0.552
## 
## Residual standard error: 2.85 on 99 degrees of freedom</code></pre>
<pre class="r"><code># confidence interval of the model parameter estimates
confint(model)</code></pre>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) -0.7354957 0.3954957</code></pre>
</div>
</div>
</div>
</div>
<p>Again, note that in both analyses the sample mean difference of -0.17, the <em>t</em>-statistic of -0.6 with 99 degrees of freedom (df), and the <em>p</em>-value of 0.55 are identical with respective to place of rounding.</p>
<p><BR><BR><BR></p>
</div>
<div id="independent-samples-t-test" class="section level2">
<h2>Independent Samples <em>t</em>-Test</h2>
<p>For this analysis, let’s say that I was interested in understanding if level of self-confidence is different after viewing my blog than after visiting a news website. Self-condfidence was measured using the same measure from the prior analysis.</p>
<p>Let’s say that I randomly assigned 100 participants to either visit my blog or visit a news website, and measured their level of self-confidence afterwards. Those were visited my blog were coded as 0.5 while those who visited a news website were coded as -0.5 under the variable condition.</p>
<pre class="r"><code>self_confidence &lt;- sample(-3:3,100,replace = T)

# set x to  random groups
condition &lt;- sample(-0.5:0.5,100,replace=T)

# save the variables into a dataframe as dataset
dataset &lt;- data.frame(self_confidence, condition)

# view the dataset
head(dataset)</code></pre>
<pre><code>##   self_confidence condition
## 1               0      -0.5
## 2               2       0.5
## 3               2      -0.5
## 4               2      -0.5
## 5               0       0.5
## 6               1      -0.5</code></pre>
<pre class="r"><code># describe the the variable Y for each of the groups
describeBy(dataset$self_confidence, group=dataset$condition)</code></pre>
<pre><code>## 
##  Descriptive statistics by group 
## group: -0.5
##    vars  n  mean   sd median trimmed  mad min max range skew kurtosis   se
## X1    1 48 -0.02 1.88      0   -0.02 2.22  -3   3     6 0.12    -1.15 0.27
## -------------------------------------------------------- 
## group: 0.5
##    vars  n mean   sd median trimmed  mad min max range  skew kurtosis   se
## X1    1 52 0.37 1.97      0    0.45 2.97  -3   3     6 -0.16    -1.19 0.27</code></pre>
<p><BR></p>
<p>Again, let’s compare the null and research hypotheses before we perform the analyses.</p>
<p><BR></p>
<div class="divTable">
<div class="divTableBody">
<div class="divTableRow">
<div class="divTableCell" style="width: 50%; text-align: center">
<CENTER>
<strong>Independent Samples <em>t</em>-test</strong>
</CENTER>
<p><span class="math inline">\(H_0: \mu_{Blog} - \mu_{News} = 0\)</span> or equivalently <span class="math inline">\(\mu_{Blog} = \mu_{News}\)</span> <BR><span class="math inline">\(H_1: \mu_{Blog} - \mu_{News} \ne 0\)</span> or equivalently <span class="math inline">\(\mu_{Blog} = \mu_{News}\)</span></p>
</div>
<div class="divTableCell" style="width: 50%; text-align: center">
<CENTER>
<strong>GLM</strong>
</CENTER>
<p><span class="math inline">\(Model: Self\_Confidence = \beta_0 + \beta_1*Condition + \varepsilon\)</span> <span class="math inline">\(H_0: \beta_1 = 0\)</span> <BR><span class="math inline">\(H_1: \beta_1 \ne 0\)</span></p>
</div>
</div>
</div>
</div>
<div class="divTable">
<div class="divTableBody">
<div class="divTableRow">
<div class="divTableCell" style="width: 50%">
<CENTER>
<strong>Independent Samples <em>t</em>-test</strong>
</CENTER>
<pre class="r"><code># independent samples t-test
t.test(self_confidence ~ condition, var.equal=TRUE)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  self_confidence by condition
## t = -0.99977, df = 98, p-value = 0.3199
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.1528324  0.3803965
## sample estimates:
## mean in group -0.5  mean in group 0.5 
##        -0.02083333         0.36538462</code></pre>
</div>
<div class="divTableCell" style="width: 50%">
<CENTER>
<strong>GLM</strong>
</CENTER>
<pre class="r"><code># GLM
model &lt;- lm(self_confidence ~ condition)

# summary of the GLM
summary(model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = self_confidence ~ condition)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.3654 -1.3654 -0.1723  1.6346  3.0208 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.1723     0.1932   0.892    0.375
## condition     0.3862     0.3863   1.000    0.320
## 
## Residual standard error: 1.93 on 98 degrees of freedom
## Multiple R-squared:  0.0101, Adjusted R-squared:  -4.678e-06 
## F-statistic: 0.9995 on 1 and 98 DF,  p-value: 0.3199</code></pre>
<pre class="r"><code># confidence interval of the GLM parameter esimates 
confint(model)</code></pre>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) -0.2110316 0.5555829
## condition   -0.3803965 1.1528324</code></pre>
</div>
</div>
</div>
</div>
<p>Note that in both analyses the <em>t</em>-statistic of 1 with 98 degrees of freedom (df), and <em>p</em>-value of 0.32 are identical.</p>
<p><BR><BR><BR></p>
</div>
<div id="one-way-anova" class="section level2">
<h2>One-Way ANOVA</h2>
<pre class="r"><code>y &lt;- rnorm(1:15)
x &lt;- c(&quot;group1&quot;,&quot;group1&quot;,&quot;group1&quot;,&quot;group1&quot;,&quot;group1&quot;,&quot;group2&quot;,&quot;group2&quot;,&quot;group2&quot;,&quot;group2&quot;,&quot;group2&quot;,&quot;group3&quot;,&quot;group3&quot;,&quot;group3&quot;,&quot;group3&quot;,&quot;group3&quot;)
dataset &lt;- data.frame(y, x)
dataset</code></pre>
<pre><code>##              y      x
## 1  -3.38200387 group1
## 2   0.63796243 group1
## 3  -0.05292127 group1
## 4  -0.16189419 group1
## 5  -0.09686955 group1
## 6   0.34649815 group2
## 7   1.24055063 group2
## 8   0.67346533 group2
## 9  -0.27765638 group2
## 10  2.26631454 group2
## 11 -0.68193816 group3
## 12 -1.32804462 group3
## 13 -1.46228278 group3
## 14 -0.19167381 group3
## 15 -0.12288087 group3</code></pre>
<pre class="r"><code>describeBy(dataset$y, group = x)</code></pre>
<pre><code>## 
##  Descriptive statistics by group 
## group: group1
##    vars n  mean   sd median trimmed mad   min  max range  skew kurtosis
## X1    1 5 -0.61 1.58   -0.1   -0.61 0.1 -3.38 0.64  4.02 -0.96    -1.04
##      se
## X1 0.71
## -------------------------------------------------------- 
## group: group2
##    vars n mean   sd median trimmed  mad   min  max range skew kurtosis
## X1    1 5 0.85 0.96   0.67    0.85 0.84 -0.28 2.27  2.54  0.3    -1.67
##      se
## X1 0.43
## -------------------------------------------------------- 
## group: group3
##    vars n  mean   sd median trimmed  mad   min   max range  skew kurtosis
## X1    1 5 -0.76 0.62  -0.68   -0.76 0.83 -1.46 -0.12  1.34 -0.08    -2.18
##      se
## X1 0.28</code></pre>
<div class="divTable">
<div class="divTableBody">
<div class="divTableRow">
<div class="divTableCell" style="width: 50%">
<CENTER>
<strong>Typical</strong>
</CENTER>
<pre class="r"><code>model &lt;- aov(y ~ x)
anova(model)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: y
##           Df  Sum Sq Mean Sq F value Pr(&gt;F)  
## x          2  7.8982  3.9491  3.1011 0.0821 .
## Residuals 12 15.2815  1.2735                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div class="divTableCell" style="width: 50%">
<CENTER>
<strong>GLM</strong>
</CENTER>
<pre class="r"><code>model &lt;- lm(y ~ x)
anova(model)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: y
##           Df  Sum Sq Mean Sq F value Pr(&gt;F)  
## x          2  7.8982  3.9491  3.1011 0.0821 .
## Residuals 12 15.2815  1.2735                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7709 -0.5370  0.3907  0.5620  1.4165 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  -0.6111     0.5047  -1.211   0.2492  
## xgroup2       1.4610     0.7137   2.047   0.0632 .
## xgroup3      -0.1462     0.7137  -0.205   0.8411  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.128 on 12 degrees of freedom
## Multiple R-squared:  0.3407, Adjusted R-squared:  0.2309 
## F-statistic: 3.101 on 2 and 12 DF,  p-value: 0.0821</code></pre>
<pre class="r"><code>confint(model)</code></pre>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) -1.7107251 0.4884345
## xgroup2     -0.0940609 3.0160204
## xgroup3     -1.7012594 1.4088219</code></pre>
</div>
</div>
</div>
</div>
<p><BR><BR><BR></p>
</div>
<div id="factorial-anova" class="section level2">
<h2>Factorial ANOVA</h2>
<pre class="r"><code>y &lt;- rnorm(1:15)
x1 &lt;- c(&quot;group1&quot;,&quot;group1&quot;,&quot;group1&quot;,&quot;group1&quot;,&quot;group1&quot;,&quot;group2&quot;,&quot;group2&quot;,&quot;group2&quot;,&quot;group2&quot;,&quot;group2&quot;,&quot;group3&quot;,&quot;group3&quot;,&quot;group3&quot;,&quot;group3&quot;,&quot;group3&quot;)
x2 &lt;- c(&quot;group1&quot;,&quot;group2&quot;,&quot;group3&quot;,&quot;group1&quot;,&quot;group2&quot;,&quot;group3&quot;,&quot;group1&quot;,&quot;group2&quot;,&quot;group3&quot;,&quot;group1&quot;,&quot;group2&quot;,&quot;group3&quot;,&quot;group1&quot;,&quot;group2&quot;,&quot;group3&quot;)
dataset &lt;- data.frame(y, x1, x2)
dataset</code></pre>
<pre><code>##              y     x1     x2
## 1   0.01041424 group1 group1
## 2  -1.44529092 group1 group2
## 3  -0.76098700 group1 group3
## 4   0.22852054 group1 group1
## 5  -0.48068989 group1 group2
## 6   1.92753929 group2 group3
## 7  -1.67706138 group2 group1
## 8  -0.98249130 group2 group2
## 9  -1.18041377 group2 group3
## 10 -0.33457375 group2 group1
## 11 -0.89943161 group3 group2
## 12 -1.35428013 group3 group3
## 13 -0.84106251 group3 group1
## 14  0.55108063 group3 group2
## 15  1.57463625 group3 group3</code></pre>
<pre class="r"><code>describeBy(dataset$y, group = list(dataset$x1, dataset$x2))</code></pre>
<pre><code>## 
##  Descriptive statistics by group 
## : group1
## : group1
##    vars n mean   sd median trimmed  mad  min  max range skew kurtosis   se
## X1    1 2 0.12 0.15   0.12    0.12 0.16 0.01 0.23  0.22    0    -2.75 0.11
## -------------------------------------------------------- 
## : group2
## : group1
##    vars n  mean   sd median trimmed mad   min   max range skew kurtosis
## X1    1 2 -1.01 0.95  -1.01   -1.01   1 -1.68 -0.33  1.34    0    -2.75
##      se
## X1 0.67
## -------------------------------------------------------- 
## : group3
## : group1
##    vars n  mean sd median trimmed mad   min   max range skew kurtosis se
## X1    1 1 -0.84 NA  -0.84   -0.84   0 -0.84 -0.84     0   NA       NA NA
## -------------------------------------------------------- 
## : group1
## : group2
##    vars n  mean   sd median trimmed  mad   min   max range skew kurtosis
## X1    1 2 -0.96 0.68  -0.96   -0.96 0.72 -1.45 -0.48  0.96    0    -2.75
##      se
## X1 0.48
## -------------------------------------------------------- 
## : group2
## : group2
##    vars n  mean sd median trimmed mad   min   max range skew kurtosis se
## X1    1 1 -0.98 NA  -0.98   -0.98   0 -0.98 -0.98     0   NA       NA NA
## -------------------------------------------------------- 
## : group3
## : group2
##    vars n  mean   sd median trimmed  mad  min  max range skew kurtosis
## X1    1 2 -0.17 1.03  -0.17   -0.17 1.08 -0.9 0.55  1.45    0    -2.75
##      se
## X1 0.73
## -------------------------------------------------------- 
## : group1
## : group3
##    vars n  mean sd median trimmed mad   min   max range skew kurtosis se
## X1    1 1 -0.76 NA  -0.76   -0.76   0 -0.76 -0.76     0   NA       NA NA
## -------------------------------------------------------- 
## : group2
## : group3
##    vars n mean  sd median trimmed mad   min  max range skew kurtosis   se
## X1    1 2 0.37 2.2   0.37    0.37 2.3 -1.18 1.93  3.11    0    -2.75 1.55
## -------------------------------------------------------- 
## : group3
## : group3
##    vars n mean   sd median trimmed  mad   min  max range skew kurtosis
## X1    1 2 0.11 2.07   0.11    0.11 2.17 -1.35 1.57  2.93    0    -2.75
##      se
## X1 1.46</code></pre>
<div class="divTable">
<div class="divTableBody">
<div class="divTableRow">
<div class="divTableCell" style="width: 50%">
<CENTER>
<strong>Typical</strong>
</CENTER>
<pre class="r"><code>model &lt;- aov(y ~ x1*x2)
anova(model)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: y
##           Df  Sum Sq Mean Sq F value Pr(&gt;F)
## x1         2  0.2574 0.12870  0.0668 0.9361
## x2         2  1.3124 0.65619  0.3405 0.7243
## x1:x2      4  2.8138 0.70346  0.3651 0.8257
## Residuals  6 11.5611 1.92685</code></pre>
</div>
<div class="divTableCell" style="width: 50%">
<CENTER>
<strong>GLM</strong>
</CENTER>
<pre class="r"><code>model &lt;- lm(y ~ x1*x2)
anova(model)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: y
##           Df  Sum Sq Mean Sq F value Pr(&gt;F)
## x1         2  0.2574 0.12870  0.0668 0.9361
## x2         2  1.3124 0.65619  0.3405 0.7243
## x1:x2      4  2.8138 0.70346  0.3651 0.8257
## Residuals  6 11.5611 1.92685</code></pre>
<pre class="r"><code>summary(model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 * x2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.5540 -0.5768  0.0000  0.5768  1.5540 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)         0.1195     0.9815   0.122    0.907
## x1group2           -1.1253     1.3881  -0.811    0.449
## x1group3           -0.9605     1.7001  -0.565    0.593
## x2group2           -1.0825     1.3881  -0.780    0.465
## x2group3           -0.8805     1.7001  -0.518    0.623
## x1group2:x2group2   1.1058     2.1948   0.504    0.632
## x1group3:x2group2   1.7493     2.1948   0.797    0.456
## x1group2:x2group3   2.2598     2.1948   1.030    0.343
## x1group3:x2group3   1.8317     2.4043   0.762    0.475
## 
## Residual standard error: 1.388 on 6 degrees of freedom
## Multiple R-squared:  0.2749, Adjusted R-squared:  -0.6918 
## F-statistic: 0.2844 on 8 and 6 DF,  p-value: 0.9477</code></pre>
<pre class="r"><code>confint(model)</code></pre>
<pre><code>##                       2.5 %   97.5 %
## (Intercept)       -2.282280 2.521215
## x1group2          -4.521869 2.271299
## x1group3          -5.120479 3.199419
## x2group2          -4.479042 2.314126
## x2group3          -5.040403 3.279494
## x1group2:x2group2 -4.264687 6.476255
## x1group3:x2group2 -3.621126 7.119816
## x1group2:x2group3 -3.110636 7.630305
## x1group3:x2group3 -4.051361 7.714751</code></pre>
</div>
</div>
</div>
</div>
<p><BR><BR><BR></p>
</div>
<div id="correlation" class="section level2">
<h2>Correlation</h2>
<pre class="r"><code>y &lt;- rnorm(1:10)
x &lt;- rnorm(1:10)
dataset &lt;- data.frame(y,x)
dataset</code></pre>
<pre><code>##               y            x
## 1  -0.149844821 -0.197325371
## 2   0.176099830 -0.979028237
## 3   1.105325626 -0.767253560
## 4  -1.094318999 -1.419323808
## 5  -1.184360063  0.832613723
## 6  -0.822729330  2.130996588
## 7   0.010108512  0.868508269
## 8  -0.863943756  0.763008511
## 9  -0.004959571  0.295341429
## 10 -0.522150974 -0.001374946</code></pre>
<pre class="r"><code>describe(dataset)</code></pre>
<pre><code>##   vars  n  mean   sd median trimmed  mad   min  max range skew kurtosis
## y    1 10 -0.34 0.70  -0.34   -0.41 0.74 -1.18 1.11  2.29 0.54    -0.79
## x    2 10  0.15 1.06   0.15    0.10 1.04 -1.42 2.13  3.55 0.21    -1.03
##     se
## y 0.22
## x 0.33</code></pre>
<div class="divTable">
<div class="divTableBody">
<div class="divTableRow">
<div class="divTableCell" style="width: 50%">
<CENTER>
<strong>Typical</strong>
</CENTER>
<pre class="r"><code>cor.test(x, y)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  x and y
## t = -1.0462, df = 8, p-value = 0.3261
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.8014757  0.3617244
## sample estimates:
##        cor 
## -0.3469114</code></pre>
</div>
<div class="divTableCell" style="width: 50%">
<CENTER>
<strong>GLM</strong>
</CENTER>
<pre class="r"><code>model &lt;- lm(scale(y) ~ scale(x))
anova(model)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: scale(y)
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## scale(x)   1 1.0831 1.08313  1.0945 0.3261
## Residuals  8 7.9169 0.98961</code></pre>
<pre class="r"><code>summary(model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = scale(y) ~ scale(x))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.59657 -0.49287  0.05255  0.47612  1.74639 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  5.875e-17  3.146e-01   0.000    1.000
## scale(x)    -3.469e-01  3.316e-01  -1.046    0.326
## 
## Residual standard error: 0.9948 on 8 degrees of freedom
## Multiple R-squared:  0.1203, Adjusted R-squared:  0.01039 
## F-statistic: 1.095 on 1 and 8 DF,  p-value: 0.3261</code></pre>
<pre class="r"><code>confint(model)</code></pre>
<pre><code>##                 2.5 %    97.5 %
## (Intercept) -0.725424 0.7254240
## scale(x)    -1.111575 0.4177526</code></pre>
</div>
</div>
</div>
</div>
<p>Some may have learned these analyses under different names. For example, some may have learned the dependent samples <em>t</em>-test was called paired or matched samples <em>t</em>-test. Regardless of the specific nomenclature, these are generally the analyses I have seen covered from being a graduate teaching assistant for statistics courses in psychology as well as from being a tutor of statistics courses.</p>
<p>Note that the test statistic and its respective <em>p</em>-value are identical using either method (i.e., the typical univariate introductory statistics for psychology vs. GLM). Also, note that the GLM provides the same information as the ANOVA with the addition of 1 degree of freedom (<em>df</em>) tests. Thus, to take advantage of the 1 <em>df</em> test with categorical predictors (e.g., in the ANOVA), meaningful <em>a priori</em> contrasts are preferred over pre-programmed contrasts, especially in research.</p>
<p>In either case, APA format of these results would be something like the following: <em>M</em> = 0.17, 95% CI [-0.21, -0.38] <em>t</em>(98) = 0.19, <em>p</em> = 0.39</p>
</div>

</div> <!-- articleBandContent -->
</div> <!-- pageContent -->
</div> <!-- forPagesWithTOC -->
<footer class="footer">
  <div class="divTable">
    <div class="divTableBody">
      <div class="divTableRow">
        <div class="container">
          <div class="divTableCellFooter">
            &copy; 2018 Ekarin Eric Pongpipat, M.A. All rights reserved.
          </div>
          <div class="divTableCellFooter" style="width: 50px">
            <a href="mailto:epongpipat@gmail.com"><img src="images/logo_email.png" border="0" style="height: 20px;" alt="Email" class="imgLink"></a>
          </div>
          <div class="divTableCellFooter" style="width: 50px">
            <a href="https://www.linkedin.com/in/epongpipat/"><img src="images/logo_linkedin.png" border="0" style="height: 20px;" alt="LinkedIn" class="imgLink"></a>
          </div>
          <div class="divTableCellFooter" style="width: 50px">
            <a href="https://github.com/epongpipat"><img src="images/logo_github.png" border="0" style="height: 20px;" alt="GitHub" class="imgLink"></a>
          </div>
          <div class="divTableCellFooter" style="width: 50px">
            <a href="https://www.researchgate.net/profile/Ekarin_Pongpipat"><img src="images/logo_researchgate.png" border="0" style="height: 20px;" alt="ResearchGate" class="imgLink"></a>
          </div>
        </div>
      </div>
    </div>
  </div>
</footer>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
